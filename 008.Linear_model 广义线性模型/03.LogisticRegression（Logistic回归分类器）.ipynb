{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression\n",
    "(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=’warn’, max_iter=100, multi_class=’warn’, verbose=0, warm_start=False, n_jobs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=red>penalty</font>: str, 'l1' or 'l2', default: 'l2'   \n",
    "用于指定处罚中使用的规范。“newton-cg”、“sag”和“lbfgs”解决程序只支持l2点球。新版本0.19:l1惩罚与传奇求解器(允许“多项式”+ l1)\n",
    "* <font color=red>dual</font>: bool, default: False   \n",
    "对偶或原始配方。对偶公式仅适用于用liblinear求解器求解l2。当n_samples > n_features时,dual=False。\n",
    "* <font color=red>tol</font>: float, default: 1e-4   \n",
    "停止标准的公差。\n",
    "* <font color=red>C</font>: float, default: 1.0   \n",
    "正则化强度逆;必须是正数。与支持向量机一样，较小的值指定了更强的正则化。\n",
    "* <font color=red>fit_intercept</font>: bool, default: True   \n",
    "指定是否应该将常数(即偏差或拦截)添加到决策函数中。\n",
    "* <font color=red>intercept_scaling</font>: float, default 1  \n",
    "只有在使用求解器“liblinear”和self时才有用。fit_intercept设置为True。在这种情况下，x变成[x, self.intercept_scaling]，即在实例向量中附加一个与intercept_scale值相等的“合成”特征。拦截变成拦截缩放* synthetic_feature_weight。注意!合成特征的权值与其他特征一样服从l1/l2正则化。为了减少正则化对合成特征权值(从而对截距)的影响，拦截尺度必须增加。\n",
    "* <font color=red>class_weight</font>: dict or 'balanced', default: None  \n",
    "与表单{class_label: weight}中的类关联的权重。如果没有给出，所有类的权值都应该是1。“balanced”模式使用y的值作为n_samples / (n_classes * np.bincount(y))自动调整权重，权重与输入数据中的类频率成反比。注意，如果指定sample_weight，这些权重将与sample_weight相乘(通过fit方法传递)。\n",
    "* <font color=red>random_state</font>: int, RandomState instance or None, optional, default: None  \n",
    "对数据进行变换时使用的伪随机数发生器的种子。如果是int, random_state是随机数生成器使用的种子;如果是RandomState实例，random_state是随机数生成器;如果没有，随机数生成器是np.random使用的RandomState实例。solver== 'sag'或'liblinear'时使用。\n",
    "* <font color=red>solver</font>: str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, default: 'liblinear'  \n",
    "  - 算法用于优化问题。\n",
    "  对于小型数据集，“liblinear”是一个不错的选择，而对于大型数据集，“sag”和“saga”更快。  \n",
    "  对于多类问题，只有“newton-cg”、“sag”、“saga”和“lbfgs”才能处理多项损失;“liblinear”只适用于一种方案。  \n",
    "  “newton-cg”、“lbfgs”和“sag”只处理L2，而“liblinear”和“saga”只处理L1。  \n",
    "  请注意，“sag”和“saga”的快速收敛只保证在具有大致相同规模的特性上。您可以使用来自sklearn.preprocessing的标量对数据进行预处理。  \n",
    "  新版本0.17:随机平均梯度下降求解。  \n",
    "  新版本0.19:SAGA solver。  \n",
    "  0.20版本更改:默认将在0.22中从“liblinear”更改为“lbfgs”。\n",
    "* <font color=red>max_iter</font>: int, default: 100   \n",
    "适用于newton-cg、sag和lbfgs解算器。求解器收敛所需的最大迭代次数。\n",
    "* <font color=red>multi_class</font>: str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'  \n",
    "“ovr”，那么每个标签都适用一个二进制问题。对于“多项式”，损失最小的是整个概率分布的多项式损失，即使数据是二进制的。  \n",
    "solver=“liblinear”,“多项式”不可用。如果数据是二进制的，“auto”选择“ovr”，或者如果solver=“liblinear”，则选择“多项式”。  \n",
    "新版本0.18:随机平均梯度下降求解“多项式”情况。  \n",
    "版本0.20中更改:默认值将在0.22中从“ovr”更改为“auto”。详细:int，默认值:0  \n",
    "对于liblinear和lbfgs，求解器将详细设置为任何正数表示详细。\n",
    "* <font color=red>warm_start</font>: bool, default: False  \n",
    "当设置为True时，重用前一个调用的解决方案，以适合作为初始化，否则，只需擦除前一个解决方案。对liblinear求解器无用。查看术语表。  \n",
    "新版本0.17:warm_start支持lbfgs、newton-cg、sag、saga解决程序。\n",
    "* <font color=red>n_jobs</font>: int or None, optional (default=None)  \n",
    "如果multi_class='ovr' 并行化类时使用的CPU内核数量。无论是否指定“multi_class”，当求解器被设置为“liblinear”时，该参数都将被忽略。没有一个意思是1，除非是在工作中。parallel_backend上下文。-1表示使用所有处理器。有关详细信息，请参见Glossary。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\work tools\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial').fit(X, y)\n",
    "clf.predict(X[:2, :])\n",
    "\n",
    "clf.predict_proba(X[:2, :]) \n",
    "\n",
    "\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
